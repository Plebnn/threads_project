{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cbfc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, SimpleDirectoryReader ,VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "import json\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core.agent.workflow import ReActAgent\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.core.agent.workflow import AgentStream, ToolCallResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "113a616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model= \"gemma3:12b\",\n",
    "    request_timeout=120.0,\n",
    "    context_window=8128,\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size=512\n",
    "Settings.chunk_overlap=64\n",
    "\n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"snowflake-arctic-embed2:latest\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62fe496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./VectorStorage/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./VectorStorage/index_store.json.\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(persist_dir=\"./VectorStorage\")\n",
    "index = load_index_from_storage(storage_context=storage_context)\n",
    "query_engine = index.as_query_engine(llm=Settings.llm,similarity_tok_k=5)\n",
    "query_engine_tool = QueryEngineTool.from_defaults(query_engine=query_engine, name=\"RAG_Lookup_tool\", description=\"Query engine tool to look up a knowledge base of documents regarding climate change\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acbc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = \"Wir als deutche machen sowieso nur 2% des CO2 aussoßes. Warum sollten wir dann was machen???!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d475aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tweet = \"Die sonne scheint einfach mehr, es gib gar keinen klimawandel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6190d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_original_tweet =  await llm.acomplete(f\"This tweet is in german, translate it into english. Do not include any other words than the tweet: {class_tweet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa2382e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\"The sun simply shines more, there's no climate change.\", additional_kwargs={'tool_calls': None, 'thinking': None}, raw={'model': 'gemma3:12b', 'created_at': '2025-08-06T06:24:58.836738066Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4658685983, 'load_duration': 4176783591, 'prompt_eval_count': 44, 'prompt_eval_duration': 264047719, 'eval_count': 14, 'eval_duration': 217286037, 'message': Message(role='assistant', content=\"The sun simply shines more, there's no climate change.\", thinking=None, images=None, tool_calls=None), 'usage': {'prompt_tokens': 44, 'completion_tokens': 14, 'total_tokens': 58}}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_original_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d15ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "        This is a tweet from Twitter:\n",
    "        \"{translated_original_tweet.text}\"\n",
    "        Workflow: \n",
    "        2) Extract the claims in the tweet. If you don't find any relevant data answer on common knowledge.\n",
    "        3) Use the RAG_Lookup_tool to fact check the claims in the tweet\n",
    "        4) If the tweet contains wrong information, write an answer to the tweet in english, where you correct the wrong claims Be direct and critizise missinformation. If the tweet has no claims or all claims are correct answe with: NO_ACTION_NEEDED\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e87a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow.errors import WorkflowRuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf89c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: RAG_Lookup_tool\n",
      "Action Input: {\"input\": \"The sun simply shines more, there's no climate change.\"}\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: That's incorrect. Climate change is a real and serious threat, supported by overwhelming scientific evidence. The idea that it's simply the sun shining more is a dangerous myth that ignores decades of research."
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    agent = ReActAgent(tools=[query_engine_tool])\n",
    "    ctx = Context(agent)\n",
    "    handler = agent.run(prompt, ctx=ctx, max_iterations=30)\n",
    "\n",
    "    async for ev in handler.stream_events():\n",
    "        # if isinstance(ev, ToolCallResult):\n",
    "        #     print(f\"\\nCall {ev.tool_name} with {ev.tool_kwargs}\\nReturned: {ev.tool_output}\")\n",
    "        if isinstance(ev, AgentStream):\n",
    "            print(f\"{ev.delta}\", end=\"\", flush=True)\n",
    "\n",
    "    response = await handler\n",
    "    ro= response.model_dump()\n",
    "    answer_tweet = ro[\"response\"][\"blocks\"][0][\"text\"]\n",
    "except WorkflowRuntimeError as e:\n",
    "    print(f\"Error catched {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b36baeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's incorrect. Climate change is a real and serious threat, supported by overwhelming scientific evidence. The idea that it's simply the sun shining more is a dangerous myth that ignores decades of research.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a548d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = await llm.acomplete(f\"If this tweet is in english, translate it into german if not, repeat the tweet. Do not include any other words than the tweet: {answer_tweet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47a599d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Das ist falsch. Der Klimawandel ist eine reale und ernste Bedrohung, die durch überwältigende wissenschaftliche Beweise belegt wird. Die Vorstellung, dass es einfach nur die Sonne ist, die stärker scheint, ist ein gefährlicher Mythos, der jahrzehntelange Forschung ignoriert.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "threads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
